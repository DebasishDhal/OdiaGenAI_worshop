{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1x1N-vi5nol"
      },
      "source": [
        "# Setting up the BharatAI translation-application for English->Indic translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcf3YRS24GEL",
        "outputId": "e09a8cf4-d8b9-4a9d-d437-44fe9b13774f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'indicTrans'...\n",
            "remote: Enumerating objects: 697, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 697 (delta 278), reused 344 (delta 240), pack-reused 297\u001b[K\n",
            "Receiving objects: 100% (697/697), 2.64 MiB | 10.23 MiB/s, done.\n",
            "Resolving deltas: 100% (405/405), done.\n",
            "/content/indicTrans\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1399, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 1399 (delta 135), reused 147 (delta 120), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1399/1399), 9.57 MiB | 9.45 MiB/s, done.\n",
            "Resolving deltas: 100% (745/745), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 37.81 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 597, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 597 (delta 8), reused 12 (delta 4), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (597/597), 252.23 KiB | 2.83 MiB/s, done.\n",
            "Resolving deltas: 100% (357/357), done.\n",
            "/content\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting mock\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.2-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Collecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (5.0.2)\n",
            "Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.18.1)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.6)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.13.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.7.22)\n",
            "Installing collected packages: morfessor, tensorboardX, sacremoses, portalocker, mock, colorama, sacrebleu, sphinxcontrib-jquery, sphinx-rtd-theme, sphinx-argparse, indic-nlp-library\n",
            "Successfully installed colorama-0.4.6 indic-nlp-library-0.92 mock-5.1.0 morfessor-2.0.6 portalocker-2.8.2 sacrebleu-2.3.2 sacremoses-0.1.1 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.3.0 sphinxcontrib-jquery-4.1 tensorboardX-2.6.2.2\n",
            "Collecting mosestokenizer\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting docopt (from mosestokenizer)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openfile (from mosestokenizer)\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools (from mosestokenizer)\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting toolwrapper (from mosestokenizer)\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.10/dist-packages (from subword-nmt) (5.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from subword-nmt) (4.66.1)\n",
            "Building wheels for collected packages: mosestokenizer, docopt, toolwrapper, uctools\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49171 sha256=25d6c96b4c91d78508b58c7bff7744e85fbafd64fda20565dd15b19bc1d21f61\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/d8/15/4c5ebbe883513f003cb055a0369c77c9df857023a706f39e70\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=90f010f2cf35f25e2e56b97b73c84e7e72db1e6de0da124ecbe4671ace3af3d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3337 sha256=091d789c94fc12d8b25da62424c2cb99fbf7557219841777f55a1112bb2ec0e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/af/b1/99b57a06dda78fdcee86d2e22c64743f3b8df8f31cfc04baf7\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6147 sha256=cfadb6947fbf11c18daf7d3364518f038ef0971fa0cbd81030f1e071f97b2e67\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ee/10/33257b0801ac6a912c841939032c16da1eb3db377afe1443e5\n",
            "Successfully built mosestokenizer docopt toolwrapper uctools\n",
            "Installing collected packages: toolwrapper, openfile, docopt, uctools, subword-nmt, mosestokenizer\n",
            "Successfully installed docopt-0.6.2 mosestokenizer-1.2.1 openfile-0.0.7 subword-nmt-0.3.8 toolwrapper-2.1.0 uctools-1.3.0\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34933, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 34933 (delta 56), reused 53 (delta 36), pack-reused 34850\u001b[K\n",
            "Receiving objects: 100% (34933/34933), 25.10 MiB | 20.06 MiB/s, done.\n",
            "Resolving deltas: 100% (25363/25363), done.\n",
            "/content/fairseq\n",
            "Processing /content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (3.0.5)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==0.12.2)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.23.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2023.6.3)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.3.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (4.66.1)\n",
            "Collecting bitarray (from fairseq==0.12.2)\n",
            "  Downloading bitarray-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.1.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (23.2)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.5.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->fairseq==0.12.2) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=19952901 sha256=123c2c14a89cd138d9b1e34f95295bc9f0b37393c6af35fe6fcdf76a946dc65b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rrec2hrm/wheels/c6/d7/db/bc419b1daa8266aa8de2a7c4d29f62dbfa814e8701fe4695a2\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=f52514847b28ebdefcd453883b64a48cd0296a0059ff512aca759bd2f3b4c63c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, omegaconf, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.8.3 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers) (1.3.0)\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.22.post7\n",
            "/content\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cu118)\n",
            "    Python  3.10.13 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-21 21:51:52--  https://ai4b-public-nlu-nlg.objectstore.e2enetworks.net/en2indic.zip\n",
            "Resolving ai4b-public-nlu-nlg.objectstore.e2enetworks.net (ai4b-public-nlu-nlg.objectstore.e2enetworks.net)... 164.52.210.97, 164.52.206.154, 101.53.152.30, ...\n",
            "Connecting to ai4b-public-nlu-nlg.objectstore.e2enetworks.net (ai4b-public-nlu-nlg.objectstore.e2enetworks.net)|164.52.210.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4811880516 (4.5G) [application/zip]\n",
            "Saving to: ‘en2indic.zip’\n",
            "\n",
            "en2indic.zip        100%[===================>]   4.48G  18.6MB/s    in 4m 15s  \n",
            "\n",
            "2023-11-21 21:56:10 (18.0 MB/s) - ‘en2indic.zip’ saved [4811880516/4811880516]\n",
            "\n",
            "Archive:  en2indic.zip\n",
            "   creating: en-indic/\n",
            "   creating: en-indic/vocab/\n",
            "  inflating: en-indic/vocab/bpe_codes.32k.SRC  \n",
            "  inflating: en-indic/vocab/vocab.SRC  \n",
            "  inflating: en-indic/vocab/vocab.TGT  \n",
            "  inflating: en-indic/vocab/bpe_codes.32k.TGT  \n",
            "   creating: en-indic/final_bin/\n",
            "  inflating: en-indic/final_bin/preprocess.log  \n",
            "  inflating: en-indic/final_bin/dict.TGT.txt  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/dict.SRC.txt  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.TGT.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.TGT.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.SRC.idx  \n",
            "  inflating: en-indic/final_bin/train.SRC-TGT.SRC.bin  \n",
            "  inflating: en-indic/final_bin/valid.SRC-TGT.SRC.bin  \n",
            "  inflating: en-indic/final_bin/test.SRC-TGT.SRC.bin  \n",
            "   creating: en-indic/model/\n",
            "  inflating: en-indic/model/checkpoint_best.pt  \n",
            "/content/indicTrans\n",
            "Initializing vocab and bpe\n",
            "Initializing model for translation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 183.28it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['ଜନ୍ମଦିନର ଶୁଭେଚ୍ଛା! ଏହି ବିଶେଷ ଦିନ ଆପଣମାନଙ୍କ ପାଇଁ ଆନନ୍ଦ, ହସ ଏବଂ ସମସ୍ତ ଆଶୀର୍ବାଦ ଆଣିଦେଉ।',\n",
              " 'ଗତ ସଦସ୍ୟ ବୈଠକରେ କ୍ଲବକୁ ଉନ୍ନତ କରିବା ପାଇଁ 5ଟି ବିଚାର ତାଲିକା ପ୍ରସ୍ତୁତ କରାଯାଉ।',\n",
              " 'ଏକ ଷ୍ଟକର କ୍ରୟ ଏବଂ ବିକ୍ରୟର ସର୍ବାଧିକ ଲାଭ ଖୋଜିବା ପାଇଁ ଏକ ଆଲଗୋରିଦମ ପ୍ରସ୍ତୁତ କରିବେ କି?']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd indicTrans\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd ..\n",
        "!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
        "! pip install mosestokenizer subword-nmt\n",
        "# Install fairseq from source\n",
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "%cd fairseq\n",
        "# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
        "!pip install ./\n",
        "! pip install xformers\n",
        "%cd ..\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
        "# sanity check to see if fairseq is installed\n",
        "from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n",
        "!wget https://ai4b-public-nlu-nlg.objectstore.e2enetworks.net/en2indic.zip\n",
        "!unzip en2indic.zip\n",
        "\n",
        "# # downloading the indic-indic model\n",
        "# !wget https://ai4b-public-nlu-nlg.objectstore.e2enetworks.net/m2m.zip\n",
        "# !unzip m2m.zip\n",
        "\n",
        "%cd indicTrans\n",
        "from indicTrans.inference.engine import Model\n",
        "\n",
        "indic2en_model = Model(expdir='../en-indic')\n",
        "ta_sents = ['Happy birthday! May this special day bring you joy, laughter, and all the blessings you deserve. Have a wonderful year ahead!',\n",
        "            'During the last member meeting, create a list of 5 ideas to improve the club.',\n",
        "            'Design an algorithm to find the maximum profit of a stock buy and sell?']\n",
        "\n",
        "\n",
        "indic2en_model.batch_translate(ta_sents, 'en', 'or')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMBAzy7T6KdF"
      },
      "source": [
        "#Setting up the camel-ai for conversation generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QF4jQhwR4Ppn"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/camel-ai/camel.git@v0.1.0\n",
        "# !pip install openai==0.28\n",
        "\n",
        "import openai\n",
        "from colorama import Fore\n",
        "from camel.agents import RolePlaying\n",
        "from camel.utils import print_text_animated\n",
        "import pprint\n",
        "import random\n",
        "openai.api_key = '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' #Given to me, 03/10.23, 1900 hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9qQ41H-O5u3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "ubu9M6kkDitJ",
        "outputId": "218b7027-71a4-41b6-f6b6-3323ab93af71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original task prompt:\n",
            "Designing sustainable farming practices for small-scale farmers in the fertile plains of Punjab.\n",
            "\n",
            "Specified task prompt:\n",
            "Developing a robotic system, scientists will help farmers by creating a solar-powered, autonomous machine equipped with sensors to precisely detect and eliminate weeds in crop fields. This will reduce the need for herbicides, increase crop yield, and significantly enhance sustainable farming practices.\n",
            "\n",
            "1\n",
            "2\n",
            "******************************************************************************************************************************************************\n",
            "Number of conversations =  4\n",
            "Conversation generation done! Translation happening now!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2021.35it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 1901.75it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 2452.81it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 335.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 2493.64it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 318.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'assistant': 'Scientist',\n",
            " 'conversations': [{'from': 'user',\n",
            "                    'value': 'रोबोटिक मशीन के लिए सौर ऊर्जा प्रणाली विकसित '\n",
            "                             'करना।'},\n",
            "                   {'from': 'assistant',\n",
            "                    'value': 'रोबोटिक मशीन के लिए एक सौर ऊर्जा प्रणाली विकसित '\n",
            "                             'करने के लिए, हम निम्नलिखित घटकों को डिजाइन और '\n",
            "                             'लागू कर सकते हैंः 1. सौर पैनलः रोबोटिक मशीन पर '\n",
            "                             'उच्च दक्षता वाले सौर पैनल स्थापित करें ताकि सूरज '\n",
            "                             'की रोशनी को पकड़ा जा सके और इसे विद्युत ऊर्जा '\n",
            "                             'में परिवर्तित किया जा सके। पैनल की संख्या और '\n",
            "                             'आकार मशीन की ऊर्जा आवश्यकताओं के आधार पर '\n",
            "                             'निर्धारित किया जाना चाहिए। 2. बैटरी स्टोरेजः दिन '\n",
            "                             'के दौरान उत्पन्न अतिरिक्त सौर ऊर्जा को स्टोर '\n",
            "                             'करने के लिए एक बैटरी स्टोरेज सिस्टम को शामिल '\n",
            "                             'करें। इससे रोबोटिक मशीन के लिए निरंतर बिजली की '\n",
            "                             'आपूर्ति सुनिश्चित होगी, यहां तक कि कम धूप की '\n",
            "                             'अवधि के दौरान या रात में भी। इस प्रणाली को ऊर्जा '\n",
            "                             'के उपयोग को अनुकूलित करते समय सेंसर, मोटर और '\n",
            "                             'अन्य महत्वपूर्ण घटकों को शक्ति प्रदान करने को '\n",
            "                             'प्राथमिकता देनी चाहिए। ऊर्जा निगरानीः बैटरी के '\n",
            "                             'ऊर्जा स्तर और रोबोटिक मशीन की समग्र बिजली खपत को '\n",
            "                             'ट्रैक करने के लिए सेंसर और निगरानी प्रणाली को '\n",
            "                             'लागू करना। इस डेटा का उपयोग ऊर्जा उपयोग को '\n",
            "                             'अनुकूलित करने और किसी भी संभावित मुद्दों या '\n",
            "                             'अक्षमताओं की पहचान करने के लिए किया जा सकता है। '\n",
            "                             '5. सुरक्षा उपायः सौर पैनल और बैटरी प्रणाली को '\n",
            "                             'अत्यधिक मौसम की स्थिति, जैसे ओले या अत्यधिक '\n",
            "                             'गर्मी के कारण होने वाले नुकसान से बचाने के लिए '\n",
            "                             'सुरक्षा तंत्र शामिल करें। यह सुरक्षात्मक कवर या '\n",
            "                             'स्वचालित रिट्रैक्शन तंत्र के उपयोग के माध्यम से '\n",
            "                             'प्राप्त किया जा सकता है। इस स्टेशन को मशीन की '\n",
            "                             'ऊर्जा आवश्यकताओं को पूरा करने के लिए अतिरिक्त '\n",
            "                             'सौर पैनल से सुसज्जित किया जा सकता है।'},\n",
            "                   {'from': 'user',\n",
            "                    'value': 'फसल के खेतों में खरपतवार का पता लगाने के लिए '\n",
            "                             'सेंसर शामिल करें।'},\n",
            "                   {'from': 'assistant',\n",
            "                    'value': 'सेंसर को शामिल करने के लिए जो फसल क्षेत्रों में '\n",
            "                             'खरपतवार का पता लगा सकते हैं, हम निम्नलिखित को '\n",
            "                             'लागू कर सकते हैंः 1. कैमेरा आधारित सेंसर: '\n",
            "                             'रोबोटिक मशीन पर उच्च-रिज़ॉल्यूशन कैमरे स्थापित '\n",
            "                             'करें ताकि फसल क्षेत्रों की छवियां ली जा सकें। इन '\n",
            "                             'कैमरों को उन्नत छवि प्रसंस्करण एल्गोरिदम से '\n",
            "                             'सुसज्जित किया जा सकता है ताकि रंग, आकार और बनावट '\n",
            "                             'जैसी उनकी दृश्य विशेषताओं के आधार पर फसलों और '\n",
            "                             'खरपतवार के बीच अंतर किया जा सके। 2. '\n",
            "                             'हाइपरस्पेक्ट्रल सेंसर: इलेक्ट्रोमैग्नेटिक '\n",
            "                             'तरंगदैर्ध्य की एक विस्तृत श्रृंखला में डेटा को '\n",
            "                             'कैप्चर करने के लिए रोबोटिक मशीन में '\n",
            "                             'हाइपरस्पेक्ट्रल सेंसर को एकीकृत करें। इस डेटा का '\n",
            "                             'उपयोग पौधों और खरपतवार के स्पेक्ट्रल हस्ताक्षर '\n",
            "                             'का विश्लेषण करने के लिए किया जा सकता है, जिससे '\n",
            "                             'विभिन्न खरपतवार प्रजातियों की पहचान और वर्गीकरण '\n",
            "                             'संभव हो सके। पौधों की ऊंचाई और संरचना का '\n",
            "                             'विश्लेषण करके, रोबोटिक मशीन उन विसंगतियों की '\n",
            "                             'पहचान कर सकती है जो खरपतवार की उपस्थिति को इंगित '\n",
            "                             'करती हैं। लिडार सेंसर उनकी भौतिक विशेषताओं के '\n",
            "                             'आधार पर फसलों और खरपतवार के बीच अंतर करने में भी '\n",
            "                             'मदद कर सकते हैं। रियल-टाइम डेटा विश्लेषणः सेंसर '\n",
            "                             'डेटा को प्रोसेस करने और तत्काल निर्णय लेने के '\n",
            "                             'लिए रोबोटिक मशीन पर रियल-टाइम डेटा विश्लेषण '\n",
            "                             'क्षमताओं को लागू करना। इसमें पूर्व-प्रशिक्षित '\n",
            "                             'मॉडल के माध्यम से डेटा को चलाना या आवश्यक गणना '\n",
            "                             'करने के लिए ऑन-बोर्ड कंप्यूटिंग शक्ति का उपयोग '\n",
            "                             'करना शामिल हो सकता है।'}],\n",
            " 'length': 4,\n",
            " 'specified_task': 'एक रोबोटिक प्रणाली विकसित करने के लिए वैज्ञानिक सौर ऊर्जा '\n",
            "                   'से चलने वाली एक स्वायत्त मशीन का निर्माण कर किसानों की मदद '\n",
            "                   'करेंगे। इससे जड़ी-बूटियों की आवश्यकता कम होगी, फसल की '\n",
            "                   'पैदावार बढ़ेगी और टिकाऊ खेती के तौर-तरीकों में उल्लेखनीय '\n",
            "                   'वृद्धि होगी।',\n",
            " 'task': 'पंजाब के उपजाऊ मैदानों में छोटे किसानों के लिए टिकाऊ कृषि पद्धतियों '\n",
            "         'की रूपरेखा तैयार करना।',\n",
            " 'user': 'Farmer'}\n"
          ]
        }
      ],
      "source": [
        "def conversation_generator(user,assistant,chat_limit=2, task = None, lang = 'en'):\n",
        "\n",
        "  if task is None: #Using few shot inference to generate a conversation topic if not specified by the user. The camel library will take care of the specific task once a topic has been assigned.\n",
        "    user, assistant = user , assistant\n",
        "\n",
        "    prompt_random = f'''User: Actor, Assistant: Business analyst\n",
        "    Generate a conversation topic: Help an actor to decide which genre of movie to choose based on recent trends\\n\n",
        "    User: Accountant, Assistant: Student\n",
        "    Generate a conversation topic: Developing a custom accounting software to automate financial processes and reduce errors in account-keeping.\\n\n",
        "    User: Athlete, Assistant: Doctor\n",
        "    Generate a conversation topic: Developing a personalized nutrition plan for a Jewish athlete, to optimize athletic performance and recovery\\n\n",
        "    User: Industrialist, Assistant: Social Media Manager\\n\n",
        "    Generate a conversation topic: Develop a social media strategy to improve the impression of the industrialist through philanthropical activites\\n\n",
        "    User: Tourist, Assistant: Guide\n",
        "    Generate a conversation topic: Discuss why and how the Colosseum was built\n",
        "    User: Student, Assistant: Consultant\n",
        "    Generate a conversation topic: Help a student to choose which stream to choose\n",
        "    User: {user}, Assistant: {assistant}\n",
        "    Generate a conversation topic:'''\n",
        "\n",
        "    prompt_india = f'''User: Farmer, Assistant: Business analyst\n",
        "    Generate a conversation topic related to India: Help a farmer from dry areas of Rajasthan in deciding the optimal choice for crops this year\\n\n",
        "    User: Accountant, Assistant: Developer\n",
        "    Generate a conversation topic related to India: Developing a custom accounting software to automate financial processes and reduce errors in Bombay Stock Exchange.\\n\n",
        "    User: Athlete, Assistant: Doctor\n",
        "    Generate a conversation topic related to India: Developing a personalized nutrition plan for a North Indian Jain athlete, to optimize athletic performance and recovery.\\n\n",
        "    User: Politician, Assistant: Social Media Manager\\n\n",
        "    Generate a conversation topic related to India: Develop a social media strategy to increase the politician's online presence and engagement with constituents to help him win Madhya Pradesh elections.\\n\n",
        "    User: Tourist, Assistant: Guide\n",
        "    Generate a conversation topic related to India: Discuss why and how Hoysala temple was built in Karnataka\n",
        "    User: Student, Assistant: Consultant\n",
        "    Generate a conversation topic related to India: Help a CBSE student to opt for either JEE or NEET entrance exam\n",
        "    User: {user}, Assistant: {assistant}\n",
        "    Generate a conversation topic related to India:'''\n",
        "\n",
        "    choice = random.choice(['global','india'])\n",
        "\n",
        "    if choice == 'global':\n",
        "      prompt = prompt_random\n",
        "      content = \"You are a helpful assistant that provides information.\"\n",
        "    else:\n",
        "      prompt = prompt_india\n",
        "      content = \"You are a helpful assistant that provides information about India.\"\n",
        "\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Use GPT-3.5 Turbo engine for chat\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": content},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    task = response.choices[0].message[\"content\"].strip()\n",
        "\n",
        "\n",
        "  task_prompt = task\n",
        "  print(f\"Original task prompt:\\n{task_prompt}\\n\")\n",
        "\n",
        "  assistant = assistant\n",
        "  user = user\n",
        "\n",
        "  role_play_session = RolePlaying(assistant, user, task_prompt)\n",
        "  print(f\"Specified task prompt:\\n{role_play_session.task_prompt}\\n\")\n",
        "\n",
        "  chat_turn_limit, n = chat_limit, 0\n",
        "  assistant_msg, _ = role_play_session.init_chat()\n",
        "\n",
        "  user_chat = []\n",
        "  assistant_chat = []\n",
        "\n",
        "  while n < chat_turn_limit:\n",
        "    n += 1\n",
        "    try:\n",
        "      (assistant_msg, _, _), (user_msg, _, _) = role_play_session.step(assistant_msg)\n",
        "      print(n)\n",
        "      assert user_msg.content is not None\n",
        "      assert assistant_msg.content is not None\n",
        "    except:\n",
        "      break\n",
        "\n",
        "    user_chat.append(user_msg.content)\n",
        "    if \"Next request.\" not in assistant_msg.content:\n",
        "      break\n",
        "\n",
        "    assistant_chat.append(assistant_msg.content)\n",
        "    if \"<CAMEL_TASK_DONE>\" in user_msg.content:\n",
        "        break\n",
        "\n",
        "  #Processing the generated conversation\n",
        "\n",
        "  final_user_convo = []\n",
        "  final_assistant_convo = []\n",
        "\n",
        "  if len(assistant_chat)==0 or len(user_chat)==0:\n",
        "    return \"Empty list\"\n",
        "\n",
        "\n",
        "  for i in range(len(user_chat)):\n",
        "\n",
        "    if (\"Next request\" in assistant_chat[i]) and (\"Instruction:\" in user_chat[i]) and (\"Input:\" in user_chat[i]):\n",
        "      final_instruction = \"\"\n",
        "      try:\n",
        "        instruction = user_chat[i].split(\"Instruction:\")[1].split(\"Input:\")[0]\n",
        "        input = user_chat[i].split(\"Input:\")[1].strip()\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      if input.strip() == 'None':\n",
        "        final_instruction = final_instruction+instruction.replace(\"\\n\",\" \")\n",
        "        final_instruction = final_instruction.strip()\n",
        "      else:\n",
        "        final_instruction = instruction.replace(\"\\n\",\" \")+\"\\ninput:\"+input #If an input is there, then add a newline after instruction, input: and then the input.\n",
        "        final_instruction = final_instruction.strip()\n",
        "\n",
        "      final_user_convo.append(final_instruction)\n",
        "      final_assistant_convo.append(assistant_chat[i].replace(\"Solution:\",\"\").replace(\"Next request.\",\"\").strip())\n",
        "\n",
        "    else:\n",
        "      break #Sometimes faulty chat gets generated. A proper convo has Next request at the end\n",
        "\n",
        "  assert (len(final_user_convo)-len(assistant_chat)) <= 1\n",
        "  # print('\\n\\n'+'End of the conversation\\n\\n')\n",
        "  print(\"*\"*150, end='\\n')\n",
        "  final_convo_list = []\n",
        "\n",
        "  for i in range(len(final_user_convo)):\n",
        "    user_convo = {\"from\":\"user\",\"value\":final_user_convo[i]}\n",
        "    assistant_convo = {\"from\":\"assistant\",\"value\":final_assistant_convo[i]}\n",
        "    final_convo_list.append(user_convo)\n",
        "    final_convo_list.append(assistant_convo)\n",
        "\n",
        "  length = len(final_convo_list)\n",
        "  print(\"Number of conversations = \", length)\n",
        "  final_json_entry = {'user':user,'assistant':assistant,'task':task_prompt,'conversations':final_convo_list, 'specified_task':role_play_session.task_prompt, 'length':length}\n",
        "  # pprint.pprint(final_json_entry)\n",
        "\n",
        "  if lang == 'en':\n",
        "    return final_json_entry\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Translating a conversation from English to Hindi or any Indic language\n",
        "  def translate_json(single_json, dest= 'hi'):\n",
        "    max_words = 130\n",
        "\n",
        "    def split_text(text, max_words=max_words): # Split the text into sentences based on full stops\n",
        "      sentences = text.split('.')\n",
        "\n",
        "      chunks = []\n",
        "      current_chunk = \"\"\n",
        "      word_count = 0\n",
        "\n",
        "      for sentence in sentences:\n",
        "          sentence = sentence.strip() + '.'\n",
        "          sentence_word_count = len(sentence.split())\n",
        "\n",
        "          if word_count + sentence_word_count <= max_words:\n",
        "              current_chunk += sentence + \" \"\n",
        "              word_count += sentence_word_count\n",
        "          else:\n",
        "              chunks.append(current_chunk.strip())\n",
        "              current_chunk = sentence + \" \"\n",
        "              word_count = sentence_word_count\n",
        "\n",
        "      if current_chunk:\n",
        "          chunks.append(current_chunk.strip())\n",
        "\n",
        "      return chunks\n",
        "\n",
        "    conversations = single_json['conversations']\n",
        "    assert len(conversations) > 0, \"Conversation is empty\"\n",
        "\n",
        "    translated_json = single_json.copy()\n",
        "\n",
        "    translated_conversation = conversations.copy() #Conversation defined as collection of all the exchanges between any given pair of user and assistant\n",
        "\n",
        "    translated_json['task'] = indic2en_model.translate_paragraph(single_json['task'], 'en', dest)\n",
        "    translated_json['specified_task'] = indic2en_model.translate_paragraph(single_json['specified_task'], 'en', dest)\n",
        "\n",
        "    for i in range(len(conversations)):\n",
        "\n",
        "      text = conversations[i]['value']\n",
        "\n",
        "      if len(text.split(\" \")) > max_words:\n",
        "        text_chunks = split_text(text)\n",
        "      else:\n",
        "        text_chunks = [text]\n",
        "\n",
        "      # pprint.pprint(text_chunks)\n",
        "\n",
        "      translated_chat = ' '.join(indic2en_model.batch_translate(text_chunks, 'en', dest)) #Chat is defined as a single exchange between a user and assistant\n",
        "      translated_conversation[i]['value'] = translated_chat\n",
        "\n",
        "    translated_json['conversations'] = translated_conversation\n",
        "\n",
        "    return translated_json\n",
        "\n",
        "  print(\"Conversation generation done! Translation happening now!\")\n",
        "  if lang == 'hi' or lang == 'hindi':\n",
        "    return translate_json(final_json_entry, dest = 'hi')\n",
        "\n",
        "\n",
        "\n",
        "sample = conversation_generator(user = 'Farmer',\n",
        "                                assistant = 'Scientist',\n",
        "                                # task = \"How to maximize the profit of a potato farmer\",\n",
        "                                lang = 'hi'\n",
        "                                )\n",
        "\n",
        "pprint.pprint(sample)\n",
        "# pprint.pprint(sample['conversations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YksbzSzYFQwG",
        "outputId": "6eae4b33-469a-423e-c98b-7197625473ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original task prompt:\n",
            "How to maximize the profit of a potato farmer\n",
            "\n",
            "Specified task prompt:\n",
            "Develop a specialized drone, equipped with sensors and AI technology, to autonomously monitor crop health and growth patterns in real-time. The scientist will collaborate with the farmer to fine-tune the drone's algorithms, ensuring accurate data collection and analysis for optimized irrigation, pest control, and fertilization decisions.\n",
            "\n",
            "******************************************************************************************************************************************************\n",
            "[{'from': 'user',\n",
            "  'value': 'Develop a list of essential crop health parameters that the drone '\n",
            "           'should monitor.'},\n",
            " {'from': 'assistant',\n",
            "  'value': 'The drone should be equipped with sensors to monitor various crop '\n",
            "           'health parameters. Here is a list of essential crop health '\n",
            "           'parameters that the drone should monitor:\\n'\n",
            "           '\\n'\n",
            "           '1. Temperature: Monitoring the temperature of the crop can help '\n",
            "           'identify stress or disease conditions. An abnormal increase or '\n",
            "           'decrease in temperature can indicate potential issues.\\n'\n",
            "           '\\n'\n",
            "           '2. Humidity: Monitoring humidity levels can provide insights into '\n",
            "           'the moisture content of the crop and help in determining '\n",
            "           'irrigation needs. High humidity can also indicate the presence of '\n",
            "           'fungal diseases.\\n'\n",
            "           '\\n'\n",
            "           '3. Soil Moisture: Measuring soil moisture levels can help optimize '\n",
            "           'irrigation practices. The drone should be equipped with sensors to '\n",
            "           'measure soil moisture at different depths to ensure proper water '\n",
            "           'management.\\n'\n",
            "           '\\n'\n",
            "           '4. Chlorophyll Content: Monitoring chlorophyll content can '\n",
            "           'indicate the overall health and photosynthetic activity of the '\n",
            "           'crop. A decrease in chlorophyll levels may indicate nutrient '\n",
            "           'deficiencies or pest damage.\\n'\n",
            "           '\\n'\n",
            "           '5. Leaf Area Index (LAI): LAI is a measure of the density and '\n",
            "           'health of the crop canopy. Monitoring LAI can help assess crop '\n",
            "           'growth and identify areas of low productivity or stress.\\n'\n",
            "           '\\n'\n",
            "           '6. Crop Height: Monitoring crop height can provide insights into '\n",
            "           'growth patterns and help identify areas of stunted or abnormal '\n",
            "           'growth.\\n'\n",
            "           '\\n'\n",
            "           '7. Weed Detection: The drone should be able to detect and '\n",
            "           'differentiate between crops and weeds. This information can help '\n",
            "           'in targeted weed control measures.\\n'\n",
            "           '\\n'\n",
            "           '8. Disease and Pest Detection: The drone should be equipped with '\n",
            "           'sensors to detect early signs of diseases and pest infestations. '\n",
            "           'This can enable timely intervention and prevent crop damage.\\n'\n",
            "           '\\n'\n",
            "           '9. Nutrient Levels: Monitoring nutrient levels in the crop can '\n",
            "           'help optimize fertilization practices. The drone should be able to '\n",
            "           'measure essential nutrients such as nitrogen, phosphorus, and '\n",
            "           'potassium.\\n'\n",
            "           '\\n'\n",
            "           '10. Canopy Temperature: Monitoring the temperature of the crop '\n",
            "           'canopy can help identify stress conditions caused by factors such '\n",
            "           'as water deficiency or pest infestation.'},\n",
            " {'from': 'user',\n",
            "  'value': 'Develop algorithms for the drone to analyze the collected data and '\n",
            "           'provide real-time insights on crop health and growth patterns.'},\n",
            " {'from': 'assistant',\n",
            "  'value': 'To develop algorithms for the drone to analyze the collected data '\n",
            "           'and provide real-time insights on crop health and growth patterns, '\n",
            "           'we can follow these steps:\\n'\n",
            "           '\\n'\n",
            "           '1. Data Collection: The drone will collect data from the various '\n",
            "           'sensors mentioned earlier, such as temperature, humidity, soil '\n",
            "           'moisture, chlorophyll content, etc. The data will be stored and '\n",
            "           'processed for analysis.\\n'\n",
            "           '\\n'\n",
            "           '2. Data Preprocessing: Before analyzing the data, we need to '\n",
            "           'preprocess it to remove any noise or outliers. This may involve '\n",
            "           'filtering the data, removing erroneous readings, or normalizing '\n",
            "           'the values.\\n'\n",
            "           '\\n'\n",
            "           '3. Feature Extraction: Next, we need to extract relevant features '\n",
            "           'from the collected data. For example, we can calculate the average '\n",
            "           'temperature, humidity, or chlorophyll content over a specific '\n",
            "           'period. These features will be used for further analysis.\\n'\n",
            "           '\\n'\n",
            "           '4. Machine Learning Models: We can utilize machine learning '\n",
            "           'algorithms to analyze the collected data and provide insights. For '\n",
            "           'example, we can use regression models to predict crop growth based '\n",
            "           'on temperature and humidity data. Classification models can be '\n",
            "           'used to identify disease or pest infestations based on sensor '\n",
            "           'readings.\\n'\n",
            "           '\\n'\n",
            "           '5. Decision Support System: The analyzed data can be used to '\n",
            "           'provide real-time insights and recommendations to the farmer. For '\n",
            "           'instance, if the drone detects low soil moisture levels, it can '\n",
            "           'suggest the need for irrigation. If it identifies a pest '\n",
            "           'infestation, it can recommend appropriate pest control measures.\\n'\n",
            "           '\\n'\n",
            "           '6. Continuous Learning: The algorithms should be designed to '\n",
            "           'continuously learn and improve over time. As more data is '\n",
            "           \"collected and analyzed, the drone's algorithms can adapt and \"\n",
            "           'refine their predictions and recommendations.\\n'\n",
            "           '\\n'\n",
            "           '7. Real-time Reporting: The drone should be able to provide '\n",
            "           'real-time reports and visualizations of the analyzed data. This '\n",
            "           'can be in the form of a dashboard accessible to the farmer, '\n",
            "           'displaying crop health metrics, growth patterns, and any detected '\n",
            "           'issues.'}]\n"
          ]
        }
      ],
      "source": [
        "#This is my original conversation generator funciton, without the translation component.\n",
        "def conversation_generator(user,assistant,chat_limit=2, task = None): #Put chat_limit = 3.\n",
        "\n",
        "  if task is None: #Using few shot inference to generate a conversation topic if not specified by the user. The camel library will take care of the specific task once a topic has been assigned.\n",
        "    user, assistant = user , assistant\n",
        "\n",
        "    prompt_odisha = f'''User: Farmer, Assistant: Business analyst\n",
        "    Generate a conversation topic to Odisha: Help a farmer from Kalahandi district in deciding the optimal choice for crops this year\\n\n",
        "    User: Accountant, Assistant: Developer\n",
        "    Generate a conversation topic to Odisha: Developing a custom accounting software to automate financial processes and reduce errors in Odisha landrecords.\\n\n",
        "    User: Athlete, Assistant: Doctor\n",
        "    Generate a conversation topic to Odisha: Developing a personalized nutrition plan for a vegeterian athlete, to optimize athletic performance and recovery.\\n\n",
        "    User: Politician, Assistant: Social Media Manager\\n\n",
        "    Generate a conversation topic related to Odisha: Develop a social media strategy to increase the politician's online presence and engagement with constituents to help him win Cuttack elections.\\n\n",
        "    User: Tourist, Assistant: Guide\n",
        "    Generate a conversation topic related to Odisha: Discuss why and how Konark temple was built\n",
        "    User: Student, Assistant: Consultant\n",
        "    Generate a conversation topic related to Odisha: Help a CHSE student to opt for either JEE or NEET entrance exam\n",
        "    User: {user}, Assistant: {assistant}\n",
        "    Generate a conversation topic related to Odisha:'''\n",
        "\n",
        "    prompt_india = f'''User: Farmer, Assistant: Business analyst\n",
        "    Generate a conversation topic to India: Help a farmer from dry areas of Rajasthan in deciding the optimal choice for crops this year\\n\n",
        "    User: Accountant, Assistant: Developer\n",
        "    Generate a conversation topic to India: Developing a custom accounting software to automate financial processes and reduce errors in Bombay Stock Exchange.\\n\n",
        "    User: Athlete, Assistant: Doctor\n",
        "    Generate a conversation topic to India: Developing a personalized nutrition plan for a North India Jain athlete, to optimize athletic performance and recovery.\\n\n",
        "    User: Politician, Assistant: Social Media Manager\\n\n",
        "    Generate a conversation topic related to India: Develop a social media strategy to increase the politician's online presence and engagement with constituents to help him win Madhya Pradesh elections.\\n\n",
        "    User: Tourist, Assistant: Guide\n",
        "    Generate a conversation topic related to India: Discuss why and how Hoysala temple was built in Karnataka\n",
        "    User: Student, Assistant: Consultant\n",
        "    Generate a conversation topic related to India: Help a CBSE student to opt for either JEE or NEET entrance exam\n",
        "    User: {user}, Assistant: {assistant}\n",
        "    Generate a conversation topic related to India:'''\n",
        "\n",
        "    choice = random.choice(['india','odisha'])\n",
        "\n",
        "    if choice == 'odisha':\n",
        "      prompt = prompt_odisha\n",
        "      content = \"You are a helpful assistant that provides information about Odisha.\"\n",
        "    else:\n",
        "      prompt = prompt_india\n",
        "      content = \"You are a helpful assistant that provides information about India.\"\n",
        "\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Use GPT-3.5 Turbo engine for chat\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": content},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    task = response.choices[0].message[\"content\"].strip()\n",
        "\n",
        "    # response = openai.Completion.create(\n",
        "    # engine=\"text-davinci-002\", #Uses the older davinci engine\n",
        "    # prompt=prompt,\n",
        "    # max_tokens=50,\n",
        "    # # max_tokens = 70\n",
        "    # n=1\n",
        "    # )\n",
        "    # task = response.choices[0].text.strip()\n",
        "\n",
        "  task_prompt = task\n",
        "  # print(Fore.YELLOW + f\"Original task prompt:\\n{task_prompt}\\n\")\n",
        "  print(f\"Original task prompt:\\n{task_prompt}\\n\")\n",
        "\n",
        "  assistant = assistant\n",
        "  user = user\n",
        "\n",
        "  role_play_session = RolePlaying(assistant, user, task_prompt)\n",
        "  # print(Fore.CYAN + f\"Specified task prompt:\\n{role_play_session.task_prompt}\\n\")\n",
        "  print(f\"Specified task prompt:\\n{role_play_session.task_prompt}\\n\")\n",
        "\n",
        "  chat_turn_limit, n = chat_limit, 0\n",
        "  assistant_msg, _ = role_play_session.init_chat()\n",
        "\n",
        "  user_chat = []\n",
        "  assistant_chat = []\n",
        "\n",
        "  while n < chat_turn_limit:\n",
        "    n += 1\n",
        "    try:\n",
        "      (assistant_msg, _, _), (user_msg, _, _) = role_play_session.step(assistant_msg)\n",
        "      assert user_msg.content is not None\n",
        "      assert assistant_msg.content is not None\n",
        "    except:\n",
        "      break\n",
        "\n",
        "    # print(Fore.BLUE + f\"AI User:\\n\\n{user_msg.content}\\n\\n\")\n",
        "    # print(f\"AI User:\\n\\n{user_msg.content}\\n\\n\")\n",
        "    user_chat.append(user_msg.content)\n",
        "    if \"Next request.\" not in assistant_msg.content:\n",
        "      break\n",
        "\n",
        "    # print(Fore.GREEN + f\"AI Assistant:\\n\\n{assistant_msg.content}\\n\\n\")\n",
        "    # print(f\"AI Assistant:\\n\\n{assistant_msg.content}\\n\\n\")\n",
        "    assistant_chat.append(assistant_msg.content)\n",
        "    if \"<CAMEL_TASK_DONE>\" in user_msg.content:\n",
        "        break\n",
        "\n",
        "  #Processing the generated conversation\n",
        "\n",
        "  final_user_convo = []\n",
        "  final_assistant_convo = []\n",
        "\n",
        "  if len(assistant_chat)==0 or len(user_chat)==0:\n",
        "    return \"Empty list\"\n",
        "\n",
        "\n",
        "  for i in range(len(user_chat)):\n",
        "\n",
        "    if (\"Next request\" in assistant_chat[i]) and (\"Instruction:\" in user_chat[i]) and (\"Input:\" in user_chat[i]):\n",
        "      final_instruction = \"\"\n",
        "      try:\n",
        "        instruction = user_chat[i].split(\"Instruction:\")[1].split(\"Input:\")[0]\n",
        "        input = user_chat[i].split(\"Input:\")[1].strip()\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      if input.strip() == 'None':\n",
        "        final_instruction = final_instruction+instruction.replace(\"\\n\",\" \")\n",
        "        final_instruction = final_instruction.strip()\n",
        "      else:\n",
        "        final_instruction = instruction.replace(\"\\n\",\" \")+\"\\ninput:\"+input #If an input is there, then add a newline after instruction, input: and then the input.\n",
        "        final_instruction = final_instruction.strip()\n",
        "\n",
        "      final_user_convo.append(final_instruction)\n",
        "      final_assistant_convo.append(assistant_chat[i].replace(\"Solution:\",\"\").replace(\"Next request.\",\"\").strip())\n",
        "\n",
        "    else:\n",
        "      break #Sometimes faulty chat gets generated. A proper convo has Next request at the end\n",
        "\n",
        "  assert (len(final_user_convo)-len(assistant_chat))<=1\n",
        "  # print('\\n\\n'+'End of the conversation\\n\\n')\n",
        "  print(\"*\"*150, end='\\n')\n",
        "  final_convo_list = []\n",
        "\n",
        "  for i in range(len(final_user_convo)):\n",
        "    user_convo = {\"from\":\"user\",\"value\":final_user_convo[i]}\n",
        "    assistant_convo = {\"from\":\"assistant\",\"value\":final_assistant_convo[i]}\n",
        "    final_convo_list.append(user_convo)\n",
        "    final_convo_list.append(assistant_convo)\n",
        "\n",
        "  length = len(final_convo_list)\n",
        "\n",
        "  final_json_entry = {'user':user,'assistant':assistant,'task':task_prompt,'conversations':final_convo_list, 'specified_task':role_play_session.task_prompt, 'length':length}\n",
        "  # pprint.pprint(final_json_entry)\n",
        "  return final_json_entry\n",
        "\n",
        "sample = conversation_generator(user = 'Farmer',\n",
        "                                assistant = 'AI Scientist',\n",
        "                                task = \"How to maximize the profit of a potato farmer\"\n",
        "                                )\n",
        "\n",
        "pprint.pprint(sample['conversations'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}